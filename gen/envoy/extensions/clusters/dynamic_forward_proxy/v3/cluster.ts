// @generated by protobuf-ts 2.9.2
// @generated from protobuf file "envoy/extensions/clusters/dynamic_forward_proxy/v3/cluster.proto" (package "envoy.extensions.clusters.dynamic_forward_proxy.v3", syntax proto3)
// tslint:disable
import type { BinaryWriteOptions } from "@protobuf-ts/runtime";
import type { IBinaryWriter } from "@protobuf-ts/runtime";
import { WireType } from "@protobuf-ts/runtime";
import type { BinaryReadOptions } from "@protobuf-ts/runtime";
import type { IBinaryReader } from "@protobuf-ts/runtime";
import { UnknownFieldHandler } from "@protobuf-ts/runtime";
import type { PartialMessage } from "@protobuf-ts/runtime";
import { reflectionMergePartial } from "@protobuf-ts/runtime";
import { MessageType } from "@protobuf-ts/runtime";
import { SocketAddress } from "../../../../config/core/v3/address";
import { Duration } from "../../../../../google/protobuf/duration";
import { UInt32Value } from "../../../../../google/protobuf/wrappers";
import { Cluster_LbPolicy } from "../../../../config/cluster/v3/cluster";
import { DnsCacheConfig } from "../../../common/dynamic_forward_proxy/v3/dns_cache";
// [#protodoc-title: Dynamic forward proxy cluster configuration]

/**
 * Configuration for the dynamic forward proxy cluster. See the :ref:`architecture overview
 * <arch_overview_http_dynamic_forward_proxy>` for more information.
 * [#extension: envoy.clusters.dynamic_forward_proxy]
 *
 * @generated from protobuf message envoy.extensions.clusters.dynamic_forward_proxy.v3.ClusterConfig
 */
export interface ClusterConfig {
    /**
     * @generated from protobuf oneof: cluster_implementation_specifier
     */
    clusterImplementationSpecifier: {
        oneofKind: "dnsCacheConfig";
        /**
         * The DNS cache configuration that the cluster will attach to. Note this configuration must
         * match that of associated :ref:`dynamic forward proxy HTTP filter configuration
         * <envoy_v3_api_field_extensions.filters.http.dynamic_forward_proxy.v3.FilterConfig.dns_cache_config>`.
         *
         * @generated from protobuf field: envoy.extensions.common.dynamic_forward_proxy.v3.DnsCacheConfig dns_cache_config = 1;
         */
        dnsCacheConfig: DnsCacheConfig;
    } | {
        oneofKind: "subClustersConfig";
        /**
         * Configuration for sub clusters, when this configuration is enabled,
         * Envoy will create an independent sub cluster dynamically for each host:port.
         * Most of the configuration of a sub cluster is inherited from the current cluster,
         * i.e. health_checks, dns_resolvers and etc.
         * And the load_assignment will be set to the only one endpoint, host:port.
         *
         * Compared to the dns_cache_config, it has the following advantages:
         *
         * 1. sub clusters will be created with the STRICT_DNS DiscoveryType,
         *    so that Envoy will use all of the IPs resolved from the host.
         *
         * 2. each sub cluster is full featured cluster, with lb_policy and health check and etc enabled.
         *
         *
         * @generated from protobuf field: envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig sub_clusters_config = 4;
         */
        subClustersConfig: SubClustersConfig;
    } | {
        oneofKind: undefined;
    };
    /**
     * If true allow the cluster configuration to disable the auto_sni and auto_san_validation options
     * in the :ref:`cluster's upstream_http_protocol_options
     * <envoy_v3_api_field_config.cluster.v3.Cluster.upstream_http_protocol_options>`
     *
     * @generated from protobuf field: bool allow_insecure_cluster_options = 2;
     */
    allowInsecureClusterOptions: boolean;
    /**
     * If true allow HTTP/2 and HTTP/3 connections to be reused for requests to different
     * origins than the connection was initially created for. This will only happen when the
     * resolved address for the new connection matches the peer address of the connection and
     * the TLS certificate is also valid for the new hostname. For example, if a connection
     * has previously been established to foo.example.com at IP 1.2.3.4 with a certificate
     * that is valid for `*.example.com`, then this connection could be used for requests to
     * bar.example.com if that also resolved to 1.2.3.4.
     *
     * .. note::
     *   By design, this feature will maximize reuse of connections. This means that instead
     *   opening a new connection when an existing connection reaches the maximum number of
     *   concurrent streams, requests will instead be sent to the existing connection.
     *
     * .. note::
     *   The coalesced connections might be to upstreams that would not be otherwise
     *   selected by Envoy. See the section `Connection Reuse in RFC 7540
     *   <https://datatracker.ietf.org/doc/html/rfc7540#section-9.1.1>`_
     *
     *
     * @generated from protobuf field: bool allow_coalesced_connections = 3;
     */
    allowCoalescedConnections: boolean;
}
/**
 * Configuration for sub clusters. Hard code STRICT_DNS cluster type now.
 *
 * @generated from protobuf message envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig
 */
export interface SubClustersConfig {
    /**
     * The :ref:`load balancer type <arch_overview_load_balancing_types>` to use
     * when picking a host in a sub cluster. Note that CLUSTER_PROVIDED is not allowed here.
     *
     * @generated from protobuf field: envoy.config.cluster.v3.Cluster.LbPolicy lb_policy = 1;
     */
    lbPolicy: Cluster_LbPolicy;
    /**
     * The maximum number of sub clusters that the DFP cluster will hold. If not specified defaults to 1024.
     *
     * @generated from protobuf field: google.protobuf.UInt32Value max_sub_clusters = 2;
     */
    maxSubClusters?: UInt32Value;
    /**
     * The TTL for sub clusters that are unused. Sub clusters that have not been used in the configured time
     * interval will be purged. If not specified defaults to 5m.
     *
     * @generated from protobuf field: google.protobuf.Duration sub_cluster_ttl = 3;
     */
    subClusterTtl?: Duration;
    /**
     * Sub clusters that should be created & warmed upon creation. This might provide a
     * performance improvement, in the form of cache hits, for sub clusters that are going to be
     * warmed during steady state and are known at config load time.
     *
     * @generated from protobuf field: repeated envoy.config.core.v3.SocketAddress preresolve_clusters = 4;
     */
    preresolveClusters: SocketAddress[];
}
// @generated message type with reflection information, may provide speed optimized methods
class ClusterConfig$Type extends MessageType<ClusterConfig> {
    constructor() {
        super("envoy.extensions.clusters.dynamic_forward_proxy.v3.ClusterConfig", [
            { no: 1, name: "dns_cache_config", kind: "message", oneof: "clusterImplementationSpecifier", T: () => DnsCacheConfig },
            { no: 4, name: "sub_clusters_config", kind: "message", oneof: "clusterImplementationSpecifier", T: () => SubClustersConfig },
            { no: 2, name: "allow_insecure_cluster_options", kind: "scalar", T: 8 /*ScalarType.BOOL*/ },
            { no: 3, name: "allow_coalesced_connections", kind: "scalar", T: 8 /*ScalarType.BOOL*/ }
        ], { "udpa.annotations.versioning": { previousMessageType: "envoy.config.cluster.dynamic_forward_proxy.v2alpha.ClusterConfig" } });
    }
    create(value?: PartialMessage<ClusterConfig>): ClusterConfig {
        const message = globalThis.Object.create((this.messagePrototype!));
        message.clusterImplementationSpecifier = { oneofKind: undefined };
        message.allowInsecureClusterOptions = false;
        message.allowCoalescedConnections = false;
        if (value !== undefined)
            reflectionMergePartial<ClusterConfig>(this, message, value);
        return message;
    }
    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ClusterConfig): ClusterConfig {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* envoy.extensions.common.dynamic_forward_proxy.v3.DnsCacheConfig dns_cache_config */ 1:
                    message.clusterImplementationSpecifier = {
                        oneofKind: "dnsCacheConfig",
                        dnsCacheConfig: DnsCacheConfig.internalBinaryRead(reader, reader.uint32(), options, (message.clusterImplementationSpecifier as any).dnsCacheConfig)
                    };
                    break;
                case /* envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig sub_clusters_config */ 4:
                    message.clusterImplementationSpecifier = {
                        oneofKind: "subClustersConfig",
                        subClustersConfig: SubClustersConfig.internalBinaryRead(reader, reader.uint32(), options, (message.clusterImplementationSpecifier as any).subClustersConfig)
                    };
                    break;
                case /* bool allow_insecure_cluster_options */ 2:
                    message.allowInsecureClusterOptions = reader.bool();
                    break;
                case /* bool allow_coalesced_connections */ 3:
                    message.allowCoalescedConnections = reader.bool();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message: ClusterConfig, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter {
        /* envoy.extensions.common.dynamic_forward_proxy.v3.DnsCacheConfig dns_cache_config = 1; */
        if (message.clusterImplementationSpecifier.oneofKind === "dnsCacheConfig")
            DnsCacheConfig.internalBinaryWrite(message.clusterImplementationSpecifier.dnsCacheConfig, writer.tag(1, WireType.LengthDelimited).fork(), options).join();
        /* envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig sub_clusters_config = 4; */
        if (message.clusterImplementationSpecifier.oneofKind === "subClustersConfig")
            SubClustersConfig.internalBinaryWrite(message.clusterImplementationSpecifier.subClustersConfig, writer.tag(4, WireType.LengthDelimited).fork(), options).join();
        /* bool allow_insecure_cluster_options = 2; */
        if (message.allowInsecureClusterOptions !== false)
            writer.tag(2, WireType.Varint).bool(message.allowInsecureClusterOptions);
        /* bool allow_coalesced_connections = 3; */
        if (message.allowCoalescedConnections !== false)
            writer.tag(3, WireType.Varint).bool(message.allowCoalescedConnections);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message envoy.extensions.clusters.dynamic_forward_proxy.v3.ClusterConfig
 */
export const ClusterConfig = new ClusterConfig$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SubClustersConfig$Type extends MessageType<SubClustersConfig> {
    constructor() {
        super("envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig", [
            { no: 1, name: "lb_policy", kind: "enum", T: () => ["envoy.config.cluster.v3.Cluster.LbPolicy", Cluster_LbPolicy], options: { "validate.rules": { enum: { definedOnly: true } } } },
            { no: 2, name: "max_sub_clusters", kind: "message", T: () => UInt32Value, options: { "validate.rules": { uint32: { gt: 0 } } } },
            { no: 3, name: "sub_cluster_ttl", kind: "message", T: () => Duration, options: { "validate.rules": { duration: { gt: {} } } } },
            { no: 4, name: "preresolve_clusters", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => SocketAddress }
        ]);
    }
    create(value?: PartialMessage<SubClustersConfig>): SubClustersConfig {
        const message = globalThis.Object.create((this.messagePrototype!));
        message.lbPolicy = 0;
        message.preresolveClusters = [];
        if (value !== undefined)
            reflectionMergePartial<SubClustersConfig>(this, message, value);
        return message;
    }
    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: SubClustersConfig): SubClustersConfig {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* envoy.config.cluster.v3.Cluster.LbPolicy lb_policy */ 1:
                    message.lbPolicy = reader.int32();
                    break;
                case /* google.protobuf.UInt32Value max_sub_clusters */ 2:
                    message.maxSubClusters = UInt32Value.internalBinaryRead(reader, reader.uint32(), options, message.maxSubClusters);
                    break;
                case /* google.protobuf.Duration sub_cluster_ttl */ 3:
                    message.subClusterTtl = Duration.internalBinaryRead(reader, reader.uint32(), options, message.subClusterTtl);
                    break;
                case /* repeated envoy.config.core.v3.SocketAddress preresolve_clusters */ 4:
                    message.preresolveClusters.push(SocketAddress.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message: SubClustersConfig, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter {
        /* envoy.config.cluster.v3.Cluster.LbPolicy lb_policy = 1; */
        if (message.lbPolicy !== 0)
            writer.tag(1, WireType.Varint).int32(message.lbPolicy);
        /* google.protobuf.UInt32Value max_sub_clusters = 2; */
        if (message.maxSubClusters)
            UInt32Value.internalBinaryWrite(message.maxSubClusters, writer.tag(2, WireType.LengthDelimited).fork(), options).join();
        /* google.protobuf.Duration sub_cluster_ttl = 3; */
        if (message.subClusterTtl)
            Duration.internalBinaryWrite(message.subClusterTtl, writer.tag(3, WireType.LengthDelimited).fork(), options).join();
        /* repeated envoy.config.core.v3.SocketAddress preresolve_clusters = 4; */
        for (let i = 0; i < message.preresolveClusters.length; i++)
            SocketAddress.internalBinaryWrite(message.preresolveClusters[i], writer.tag(4, WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message envoy.extensions.clusters.dynamic_forward_proxy.v3.SubClustersConfig
 */
export const SubClustersConfig = new SubClustersConfig$Type();
