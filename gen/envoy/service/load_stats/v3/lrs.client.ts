// @generated by protobuf-ts 2.9.2
// @generated from protobuf file "envoy/service/load_stats/v3/lrs.proto" (package "envoy.service.load_stats.v3", syntax proto3)
// tslint:disable
import type { RpcTransport } from "@protobuf-ts/runtime-rpc";
import type { ServiceInfo } from "@protobuf-ts/runtime-rpc";
import { LoadReportingService } from "./lrs";
import { stackIntercept } from "@protobuf-ts/runtime-rpc";
import type { LoadStatsResponse } from "./lrs";
import type { LoadStatsRequest } from "./lrs";
import type { DuplexStreamingCall } from "@protobuf-ts/runtime-rpc";
import type { RpcOptions } from "@protobuf-ts/runtime-rpc";
// [#protodoc-title: Load reporting service (LRS)]

// Load Reporting Service is an Envoy API to emit load reports. Envoy will initiate a bi-directional
// stream with a management server. Upon connecting, the management server can send a
// :ref:`LoadStatsResponse <envoy_v3_api_msg_service.load_stats.v3.LoadStatsResponse>` to a node it is
// interested in getting the load reports for. Envoy in this node will start sending
// :ref:`LoadStatsRequest <envoy_v3_api_msg_service.load_stats.v3.LoadStatsRequest>`. This is done periodically
// based on the :ref:`load reporting interval <envoy_v3_api_field_service.load_stats.v3.LoadStatsResponse.load_reporting_interval>`
// For details, take a look at the :ref:`Load Reporting Service sandbox example <install_sandboxes_load_reporting_service>`.

/**
 * @generated from protobuf service envoy.service.load_stats.v3.LoadReportingService
 */
export interface ILoadReportingServiceClient {
    /**
     * Advanced API to allow for multi-dimensional load balancing by remote
     * server. For receiving LB assignments, the steps are:
     * 1, The management server is configured with per cluster/zone/load metric
     *    capacity configuration. The capacity configuration definition is
     *    outside of the scope of this document.
     * 2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
     *    to balance.
     *
     * Independently, Envoy will initiate a StreamLoadStats bidi stream with a
     * management server:
     * 1. Once a connection establishes, the management server publishes a
     *    LoadStatsResponse for all clusters it is interested in learning load
     *    stats about.
     * 2. For each cluster, Envoy load balances incoming traffic to upstream hosts
     *    based on per-zone weights and/or per-instance weights (if specified)
     *    based on intra-zone LbPolicy. This information comes from the above
     *    {Stream,Fetch}Endpoints.
     * 3. When upstream hosts reply, they optionally add header <define header
     *    name> with ASCII representation of EndpointLoadMetricStats.
     * 4. Envoy aggregates load reports over the period of time given to it in
     *    LoadStatsResponse.load_reporting_interval. This includes aggregation
     *    stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
     *    well as load metrics from upstream hosts.
     * 5. When the timer of load_reporting_interval expires, Envoy sends new
     *    LoadStatsRequest filled with load reports for each cluster.
     * 6. The management server uses the load reports from all reported Envoys
     *    from around the world, computes global assignment and prepares traffic
     *    assignment destined for each zone Envoys are located in. Goto 2.
     *
     * @generated from protobuf rpc: StreamLoadStats(stream envoy.service.load_stats.v3.LoadStatsRequest) returns (stream envoy.service.load_stats.v3.LoadStatsResponse);
     */
    streamLoadStats(options?: RpcOptions): DuplexStreamingCall<LoadStatsRequest, LoadStatsResponse>;
}
// [#protodoc-title: Load reporting service (LRS)]

// Load Reporting Service is an Envoy API to emit load reports. Envoy will initiate a bi-directional
// stream with a management server. Upon connecting, the management server can send a
// :ref:`LoadStatsResponse <envoy_v3_api_msg_service.load_stats.v3.LoadStatsResponse>` to a node it is
// interested in getting the load reports for. Envoy in this node will start sending
// :ref:`LoadStatsRequest <envoy_v3_api_msg_service.load_stats.v3.LoadStatsRequest>`. This is done periodically
// based on the :ref:`load reporting interval <envoy_v3_api_field_service.load_stats.v3.LoadStatsResponse.load_reporting_interval>`
// For details, take a look at the :ref:`Load Reporting Service sandbox example <install_sandboxes_load_reporting_service>`.

/**
 * @generated from protobuf service envoy.service.load_stats.v3.LoadReportingService
 */
export class LoadReportingServiceClient implements ILoadReportingServiceClient, ServiceInfo {
    typeName = LoadReportingService.typeName;
    methods = LoadReportingService.methods;
    options = LoadReportingService.options;
    constructor(private readonly _transport: RpcTransport) {
    }
    /**
     * Advanced API to allow for multi-dimensional load balancing by remote
     * server. For receiving LB assignments, the steps are:
     * 1, The management server is configured with per cluster/zone/load metric
     *    capacity configuration. The capacity configuration definition is
     *    outside of the scope of this document.
     * 2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
     *    to balance.
     *
     * Independently, Envoy will initiate a StreamLoadStats bidi stream with a
     * management server:
     * 1. Once a connection establishes, the management server publishes a
     *    LoadStatsResponse for all clusters it is interested in learning load
     *    stats about.
     * 2. For each cluster, Envoy load balances incoming traffic to upstream hosts
     *    based on per-zone weights and/or per-instance weights (if specified)
     *    based on intra-zone LbPolicy. This information comes from the above
     *    {Stream,Fetch}Endpoints.
     * 3. When upstream hosts reply, they optionally add header <define header
     *    name> with ASCII representation of EndpointLoadMetricStats.
     * 4. Envoy aggregates load reports over the period of time given to it in
     *    LoadStatsResponse.load_reporting_interval. This includes aggregation
     *    stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
     *    well as load metrics from upstream hosts.
     * 5. When the timer of load_reporting_interval expires, Envoy sends new
     *    LoadStatsRequest filled with load reports for each cluster.
     * 6. The management server uses the load reports from all reported Envoys
     *    from around the world, computes global assignment and prepares traffic
     *    assignment destined for each zone Envoys are located in. Goto 2.
     *
     * @generated from protobuf rpc: StreamLoadStats(stream envoy.service.load_stats.v3.LoadStatsRequest) returns (stream envoy.service.load_stats.v3.LoadStatsResponse);
     */
    streamLoadStats(options?: RpcOptions): DuplexStreamingCall<LoadStatsRequest, LoadStatsResponse> {
        const method = this.methods[0], opt = this._transport.mergeOptions(options);
        return stackIntercept<LoadStatsRequest, LoadStatsResponse>("duplex", this._transport, method, opt);
    }
}
