// @generated by protoc-gen-es v1.5.1
// @generated from file envoy/service/ratelimit/v3/rls.proto (package envoy.service.ratelimit.v3, syntax proto3)
/* eslint-disable */
// @ts-nocheck

import { Duration, proto3, Struct, Timestamp } from "@bufbuild/protobuf";
import { RateLimitDescriptor } from "../../../extensions/common/ratelimit/v3/ratelimit_pb.js";
import { HeaderValue } from "../../../config/core/v3/base_pb.js";

/**
 * Main message for a rate limit request. The rate limit service is designed to be fully generic
 * in the sense that it can operate on arbitrary hierarchical key/value pairs. The loaded
 * configuration will parse the request and find the most specific limit to apply. In addition,
 * a RateLimitRequest can contain multiple "descriptors" to limit on. When multiple descriptors
 * are provided, the server will limit on *ALL* of them and return an OVER_LIMIT response if any
 * of them are over limit. This enables more complex application level rate limiting scenarios
 * if desired.
 *
 * @generated from message envoy.service.ratelimit.v3.RateLimitRequest
 */
export const RateLimitRequest = proto3.makeMessageType(
  "envoy.service.ratelimit.v3.RateLimitRequest",
  () => [
    { no: 1, name: "domain", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 2, name: "descriptors", kind: "message", T: RateLimitDescriptor, repeated: true },
    { no: 3, name: "hits_addend", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
  ],
);

/**
 * A response from a ShouldRateLimit call.
 * [#next-free-field: 8]
 *
 * @generated from message envoy.service.ratelimit.v3.RateLimitResponse
 */
export const RateLimitResponse = proto3.makeMessageType(
  "envoy.service.ratelimit.v3.RateLimitResponse",
  () => [
    { no: 1, name: "overall_code", kind: "enum", T: proto3.getEnumType(RateLimitResponse_Code) },
    { no: 2, name: "statuses", kind: "message", T: RateLimitResponse_DescriptorStatus, repeated: true },
    { no: 3, name: "response_headers_to_add", kind: "message", T: HeaderValue, repeated: true },
    { no: 4, name: "request_headers_to_add", kind: "message", T: HeaderValue, repeated: true },
    { no: 5, name: "raw_body", kind: "scalar", T: 12 /* ScalarType.BYTES */ },
    { no: 6, name: "dynamic_metadata", kind: "message", T: Struct },
    { no: 7, name: "quota", kind: "message", T: RateLimitResponse_Quota },
  ],
);

/**
 * @generated from enum envoy.service.ratelimit.v3.RateLimitResponse.Code
 */
export const RateLimitResponse_Code = proto3.makeEnum(
  "envoy.service.ratelimit.v3.RateLimitResponse.Code",
  [
    {no: 0, name: "UNKNOWN"},
    {no: 1, name: "OK"},
    {no: 2, name: "OVER_LIMIT"},
  ],
);

/**
 * Defines an actual rate limit in terms of requests per unit of time and the unit itself.
 *
 * @generated from message envoy.service.ratelimit.v3.RateLimitResponse.RateLimit
 */
export const RateLimitResponse_RateLimit = proto3.makeMessageType(
  "envoy.service.ratelimit.v3.RateLimitResponse.RateLimit",
  () => [
    { no: 3, name: "name", kind: "scalar", T: 9 /* ScalarType.STRING */ },
    { no: 1, name: "requests_per_unit", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 2, name: "unit", kind: "enum", T: proto3.getEnumType(RateLimitResponse_RateLimit_Unit) },
  ],
  {localName: "RateLimitResponse_RateLimit"},
);

/**
 * Identifies the unit of of time for rate limit.
 * [#comment: replace by envoy/type/v3/ratelimit_unit.proto in v4]
 *
 * @generated from enum envoy.service.ratelimit.v3.RateLimitResponse.RateLimit.Unit
 */
export const RateLimitResponse_RateLimit_Unit = proto3.makeEnum(
  "envoy.service.ratelimit.v3.RateLimitResponse.RateLimit.Unit",
  [
    {no: 0, name: "UNKNOWN"},
    {no: 1, name: "SECOND"},
    {no: 2, name: "MINUTE"},
    {no: 3, name: "HOUR"},
    {no: 4, name: "DAY"},
    {no: 5, name: "MONTH"},
    {no: 6, name: "YEAR"},
  ],
);

/**
 * Cacheable quota for responses.
 * Quota can be granted at different levels: either for each individual descriptor or for the whole descriptor set.
 * This is a certain number of requests over a period of time.
 * The client may cache this result and apply the effective RateLimitResponse to future matching
 * requests without querying rate limit service.
 *
 * When quota expires due to timeout, a new RLS request will also be made.
 * The implementation may choose to preemptively query the rate limit server for more quota on or
 * before expiration or before the available quota runs out.
 * [#not-implemented-hide:]
 *
 * @generated from message envoy.service.ratelimit.v3.RateLimitResponse.Quota
 */
export const RateLimitResponse_Quota = proto3.makeMessageType(
  "envoy.service.ratelimit.v3.RateLimitResponse.Quota",
  () => [
    { no: 1, name: "requests", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 2, name: "valid_until", kind: "message", T: Timestamp, oneof: "expiration_specifier" },
    { no: 3, name: "id", kind: "scalar", T: 9 /* ScalarType.STRING */ },
  ],
  {localName: "RateLimitResponse_Quota"},
);

/**
 * [#next-free-field: 6]
 *
 * @generated from message envoy.service.ratelimit.v3.RateLimitResponse.DescriptorStatus
 */
export const RateLimitResponse_DescriptorStatus = proto3.makeMessageType(
  "envoy.service.ratelimit.v3.RateLimitResponse.DescriptorStatus",
  () => [
    { no: 1, name: "code", kind: "enum", T: proto3.getEnumType(RateLimitResponse_Code) },
    { no: 2, name: "current_limit", kind: "message", T: RateLimitResponse_RateLimit },
    { no: 3, name: "limit_remaining", kind: "scalar", T: 13 /* ScalarType.UINT32 */ },
    { no: 4, name: "duration_until_reset", kind: "message", T: Duration },
    { no: 5, name: "quota", kind: "message", T: RateLimitResponse_Quota },
  ],
  {localName: "RateLimitResponse_DescriptorStatus"},
);

