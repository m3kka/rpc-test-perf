// @generated by protobuf-ts 2.9.2
// @generated from protobuf file "contrib/envoy/extensions/filters/network/kafka_mesh/v3alpha/kafka_mesh.proto" (package "envoy.extensions.filters.network.kafka_mesh.v3alpha", syntax proto3)
// tslint:disable
import type { BinaryWriteOptions } from "@protobuf-ts/runtime";
import type { IBinaryWriter } from "@protobuf-ts/runtime";
import { WireType } from "@protobuf-ts/runtime";
import type { BinaryReadOptions } from "@protobuf-ts/runtime";
import type { IBinaryReader } from "@protobuf-ts/runtime";
import { UnknownFieldHandler } from "@protobuf-ts/runtime";
import type { PartialMessage } from "@protobuf-ts/runtime";
import { reflectionMergePartial } from "@protobuf-ts/runtime";
import { MessageType } from "@protobuf-ts/runtime";
// [#protodoc-title: Kafka Mesh]
// Kafka Mesh :ref:`configuration overview <config_network_filters_kafka_mesh>`.
// [#extension: envoy.filters.network.kafka_mesh]

/**
 * [#next-free-field: 6]
 *
 * @generated from protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh
 */
export interface KafkaMesh {
    /**
     * Envoy's host that's advertised to clients.
     * Has the same meaning as corresponding Kafka broker properties.
     * Usually equal to filter chain's listener config, but needs to be reachable by clients
     * (so 0.0.0.0 will not work).
     *
     * @generated from protobuf field: string advertised_host = 1;
     */
    advertisedHost: string;
    /**
     * Envoy's port that's advertised to clients.
     *
     * @generated from protobuf field: int32 advertised_port = 2;
     */
    advertisedPort: number;
    /**
     * Upstream clusters this filter will connect to.
     *
     * @generated from protobuf field: repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition upstream_clusters = 3;
     */
    upstreamClusters: KafkaClusterDefinition[];
    /**
     * Rules that will decide which cluster gets which request.
     *
     * @generated from protobuf field: repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule forwarding_rules = 4;
     */
    forwardingRules: ForwardingRule[];
    /**
     * How the consumer proxying should behave - this relates mostly to Fetch request handling.
     *
     * @generated from protobuf field: envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode consumer_proxy_mode = 5;
     */
    consumerProxyMode: KafkaMesh_ConsumerProxyMode;
}
/**
 * @generated from protobuf enum envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode
 */
export enum KafkaMesh_ConsumerProxyMode {
    /**
     * Records received are going to be distributed amongst downstream consumer connections.
     * In this mode Envoy uses librdkafka consumers pointing at upstream Kafka clusters, what means that these
     * consumers' position is meaningful and affects what records are received from upstream.
     * Users might want to take a look into these consumers' custom configuration to manage their auto-committing
     * capabilities, as it will impact Envoy's behaviour in case of restarts.
     *
     * @generated from protobuf enum value: StatefulConsumerProxy = 0;
     */
    StatefulConsumerProxy = 0
}
/**
 * [#next-free-field: 6]
 *
 * @generated from protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition
 */
export interface KafkaClusterDefinition {
    /**
     * Cluster name.
     *
     * @generated from protobuf field: string cluster_name = 1;
     */
    clusterName: string;
    /**
     * Kafka cluster address.
     *
     * @generated from protobuf field: string bootstrap_servers = 2;
     */
    bootstrapServers: string;
    /**
     * Default number of partitions present in this cluster.
     * This is especially important for clients that do not specify partition in their payloads and depend on this value for hashing.
     * The same number of partitions is going to be used by upstream-pointing Kafka consumers for consumer proxying scenarios.
     *
     * @generated from protobuf field: int32 partition_count = 3;
     */
    partitionCount: number;
    /**
     * Custom configuration passed to Kafka producer.
     *
     * @generated from protobuf field: map<string, string> producer_config = 4;
     */
    producerConfig: {
        [key: string]: string;
    };
    /**
     * Custom configuration passed to Kafka consumer.
     *
     * @generated from protobuf field: map<string, string> consumer_config = 5;
     */
    consumerConfig: {
        [key: string]: string;
    };
}
/**
 * @generated from protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule
 */
export interface ForwardingRule {
    /**
     * Cluster name.
     *
     * @generated from protobuf field: string target_cluster = 1;
     */
    targetCluster: string;
    /**
     * @generated from protobuf oneof: trigger
     */
    trigger: {
        oneofKind: "topicPrefix";
        /**
         * Intended place for future types of forwarding rules.
         *
         * @generated from protobuf field: string topic_prefix = 2;
         */
        topicPrefix: string;
    } | {
        oneofKind: undefined;
    };
}
// @generated message type with reflection information, may provide speed optimized methods
class KafkaMesh$Type extends MessageType<KafkaMesh> {
    constructor() {
        super("envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh", [
            { no: 1, name: "advertised_host", kind: "scalar", T: 9 /*ScalarType.STRING*/, options: { "validate.rules": { string: { minLen: "1" } } } },
            { no: 2, name: "advertised_port", kind: "scalar", T: 5 /*ScalarType.INT32*/, options: { "validate.rules": { int32: { gt: 0 } } } },
            { no: 3, name: "upstream_clusters", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => KafkaClusterDefinition },
            { no: 4, name: "forwarding_rules", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => ForwardingRule },
            { no: 5, name: "consumer_proxy_mode", kind: "enum", T: () => ["envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode", KafkaMesh_ConsumerProxyMode] }
        ]);
    }
    create(value?: PartialMessage<KafkaMesh>): KafkaMesh {
        const message = globalThis.Object.create((this.messagePrototype!));
        message.advertisedHost = "";
        message.advertisedPort = 0;
        message.upstreamClusters = [];
        message.forwardingRules = [];
        message.consumerProxyMode = 0;
        if (value !== undefined)
            reflectionMergePartial<KafkaMesh>(this, message, value);
        return message;
    }
    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: KafkaMesh): KafkaMesh {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string advertised_host */ 1:
                    message.advertisedHost = reader.string();
                    break;
                case /* int32 advertised_port */ 2:
                    message.advertisedPort = reader.int32();
                    break;
                case /* repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition upstream_clusters */ 3:
                    message.upstreamClusters.push(KafkaClusterDefinition.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule forwarding_rules */ 4:
                    message.forwardingRules.push(ForwardingRule.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode consumer_proxy_mode */ 5:
                    message.consumerProxyMode = reader.int32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message: KafkaMesh, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter {
        /* string advertised_host = 1; */
        if (message.advertisedHost !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.advertisedHost);
        /* int32 advertised_port = 2; */
        if (message.advertisedPort !== 0)
            writer.tag(2, WireType.Varint).int32(message.advertisedPort);
        /* repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition upstream_clusters = 3; */
        for (let i = 0; i < message.upstreamClusters.length; i++)
            KafkaClusterDefinition.internalBinaryWrite(message.upstreamClusters[i], writer.tag(3, WireType.LengthDelimited).fork(), options).join();
        /* repeated envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule forwarding_rules = 4; */
        for (let i = 0; i < message.forwardingRules.length; i++)
            ForwardingRule.internalBinaryWrite(message.forwardingRules[i], writer.tag(4, WireType.LengthDelimited).fork(), options).join();
        /* envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh.ConsumerProxyMode consumer_proxy_mode = 5; */
        if (message.consumerProxyMode !== 0)
            writer.tag(5, WireType.Varint).int32(message.consumerProxyMode);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaMesh
 */
export const KafkaMesh = new KafkaMesh$Type();
// @generated message type with reflection information, may provide speed optimized methods
class KafkaClusterDefinition$Type extends MessageType<KafkaClusterDefinition> {
    constructor() {
        super("envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition", [
            { no: 1, name: "cluster_name", kind: "scalar", T: 9 /*ScalarType.STRING*/, options: { "validate.rules": { string: { minLen: "1" } } } },
            { no: 2, name: "bootstrap_servers", kind: "scalar", T: 9 /*ScalarType.STRING*/, options: { "validate.rules": { string: { minLen: "1" } } } },
            { no: 3, name: "partition_count", kind: "scalar", T: 5 /*ScalarType.INT32*/, options: { "validate.rules": { int32: { gt: 0 } } } },
            { no: 4, name: "producer_config", kind: "map", K: 9 /*ScalarType.STRING*/, V: { kind: "scalar", T: 9 /*ScalarType.STRING*/ } },
            { no: 5, name: "consumer_config", kind: "map", K: 9 /*ScalarType.STRING*/, V: { kind: "scalar", T: 9 /*ScalarType.STRING*/ } }
        ]);
    }
    create(value?: PartialMessage<KafkaClusterDefinition>): KafkaClusterDefinition {
        const message = globalThis.Object.create((this.messagePrototype!));
        message.clusterName = "";
        message.bootstrapServers = "";
        message.partitionCount = 0;
        message.producerConfig = {};
        message.consumerConfig = {};
        if (value !== undefined)
            reflectionMergePartial<KafkaClusterDefinition>(this, message, value);
        return message;
    }
    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: KafkaClusterDefinition): KafkaClusterDefinition {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string cluster_name */ 1:
                    message.clusterName = reader.string();
                    break;
                case /* string bootstrap_servers */ 2:
                    message.bootstrapServers = reader.string();
                    break;
                case /* int32 partition_count */ 3:
                    message.partitionCount = reader.int32();
                    break;
                case /* map<string, string> producer_config */ 4:
                    this.binaryReadMap4(message.producerConfig, reader, options);
                    break;
                case /* map<string, string> consumer_config */ 5:
                    this.binaryReadMap5(message.consumerConfig, reader, options);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    private binaryReadMap4(map: KafkaClusterDefinition["producerConfig"], reader: IBinaryReader, options: BinaryReadOptions): void {
        let len = reader.uint32(), end = reader.pos + len, key: keyof KafkaClusterDefinition["producerConfig"] | undefined, val: KafkaClusterDefinition["producerConfig"][any] | undefined;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case 1:
                    key = reader.string();
                    break;
                case 2:
                    val = reader.string();
                    break;
                default: throw new globalThis.Error("unknown map entry field for field envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.producer_config");
            }
        }
        map[key ?? ""] = val ?? "";
    }
    private binaryReadMap5(map: KafkaClusterDefinition["consumerConfig"], reader: IBinaryReader, options: BinaryReadOptions): void {
        let len = reader.uint32(), end = reader.pos + len, key: keyof KafkaClusterDefinition["consumerConfig"] | undefined, val: KafkaClusterDefinition["consumerConfig"][any] | undefined;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case 1:
                    key = reader.string();
                    break;
                case 2:
                    val = reader.string();
                    break;
                default: throw new globalThis.Error("unknown map entry field for field envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition.consumer_config");
            }
        }
        map[key ?? ""] = val ?? "";
    }
    internalBinaryWrite(message: KafkaClusterDefinition, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter {
        /* string cluster_name = 1; */
        if (message.clusterName !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.clusterName);
        /* string bootstrap_servers = 2; */
        if (message.bootstrapServers !== "")
            writer.tag(2, WireType.LengthDelimited).string(message.bootstrapServers);
        /* int32 partition_count = 3; */
        if (message.partitionCount !== 0)
            writer.tag(3, WireType.Varint).int32(message.partitionCount);
        /* map<string, string> producer_config = 4; */
        for (let k of globalThis.Object.keys(message.producerConfig))
            writer.tag(4, WireType.LengthDelimited).fork().tag(1, WireType.LengthDelimited).string(k).tag(2, WireType.LengthDelimited).string(message.producerConfig[k]).join();
        /* map<string, string> consumer_config = 5; */
        for (let k of globalThis.Object.keys(message.consumerConfig))
            writer.tag(5, WireType.LengthDelimited).fork().tag(1, WireType.LengthDelimited).string(k).tag(2, WireType.LengthDelimited).string(message.consumerConfig[k]).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.KafkaClusterDefinition
 */
export const KafkaClusterDefinition = new KafkaClusterDefinition$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ForwardingRule$Type extends MessageType<ForwardingRule> {
    constructor() {
        super("envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule", [
            { no: 1, name: "target_cluster", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "topic_prefix", kind: "scalar", oneof: "trigger", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
    create(value?: PartialMessage<ForwardingRule>): ForwardingRule {
        const message = globalThis.Object.create((this.messagePrototype!));
        message.targetCluster = "";
        message.trigger = { oneofKind: undefined };
        if (value !== undefined)
            reflectionMergePartial<ForwardingRule>(this, message, value);
        return message;
    }
    internalBinaryRead(reader: IBinaryReader, length: number, options: BinaryReadOptions, target?: ForwardingRule): ForwardingRule {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string target_cluster */ 1:
                    message.targetCluster = reader.string();
                    break;
                case /* string topic_prefix */ 2:
                    message.trigger = {
                        oneofKind: "topicPrefix",
                        topicPrefix: reader.string()
                    };
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message: ForwardingRule, writer: IBinaryWriter, options: BinaryWriteOptions): IBinaryWriter {
        /* string target_cluster = 1; */
        if (message.targetCluster !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.targetCluster);
        /* string topic_prefix = 2; */
        if (message.trigger.oneofKind === "topicPrefix")
            writer.tag(2, WireType.LengthDelimited).string(message.trigger.topicPrefix);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message envoy.extensions.filters.network.kafka_mesh.v3alpha.ForwardingRule
 */
export const ForwardingRule = new ForwardingRule$Type();
